{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gridworld\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Copyright (C)                                                       #\n",
    "# 2016 Shangtong Zhang(zhangshangtong.cpp@gmail.com)                  #\n",
    "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\n",
    "# Permission given to modify the code as long as you keep this        #\n",
    "# declaration at the top                                              #\n",
    "#######################################################################\n",
    "\n",
    "def create_gridworld(world_size):\n",
    "    \"\"\"\n",
    "    world_size: height and width of the squared-shape gridworld\n",
    "    return\n",
    "        actions: list of str, possible actions\n",
    "        states: list of coordinate tuples representing all non-terminal states\n",
    "        nextState: list of list of dict, index 3 times to return the next state coordinate tuple\n",
    "    \"\"\"\n",
    "\n",
    "    # left, up, right, down\n",
    "    actions = ['L', 'U', 'R', 'D']\n",
    "\n",
    "    # Next\n",
    "    nextState = []\n",
    "    for i in range(0, WORLD_SIZE):\n",
    "        nextState.append([])\n",
    "        for j in range(0, WORLD_SIZE):\n",
    "            # Creates a dictionnary that\n",
    "            next = dict()\n",
    "            if i == 0:\n",
    "                next['U'] = (i, j)\n",
    "            else:\n",
    "                next['U'] = (i - 1, j)\n",
    "\n",
    "            if i == WORLD_SIZE - 1:\n",
    "                next['D'] = (i, j)\n",
    "            else:\n",
    "                next['D'] = (i + 1, j)\n",
    "\n",
    "            if j == 0:\n",
    "                next['L'] = (i, j)\n",
    "            else:\n",
    "                next['L'] = (i, j - 1)\n",
    "\n",
    "            if j == WORLD_SIZE - 1:\n",
    "                next['R'] = (i, j)\n",
    "            else:\n",
    "                next['R'] = (i, j + 1)\n",
    "\n",
    "            nextState[i].append(next)\n",
    "\n",
    "    states = []\n",
    "    for i in range(0, WORLD_SIZE):\n",
    "        for j in range(0, WORLD_SIZE):\n",
    "            if (i == 0 and j == 0) or (i == WORLD_SIZE - 1 and j == WORLD_SIZE - 1):\n",
    "                continue\n",
    "            else:\n",
    "                states.append((i, j))\n",
    "                \n",
    "    return actions, states, nextState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Policy : 218 iterations\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n"
     ]
    }
   ],
   "source": [
    "WORLD_SIZE = 4\n",
    "REWARD = -1.0\n",
    "EPSILON = 1e-4\n",
    "ACTION_PROBS = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "def policy_evaluation():\n",
    "    # Initializes the gridworld, our value function estimate and iteration index k\n",
    "    actions, states, nextState = create_gridworld(WORLD_SIZE)\n",
    "    V_k = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "    k = 0\n",
    "    sum_of_diffs = EPSILON + 1 # arbitrary initialization just to get into the while loop\n",
    "\n",
    "    # Policy evaluation iterates util the value function converges\n",
    "    while sum_of_diffs > EPSILON:\n",
    "\n",
    "        # Initialize our new estimation of the value function\n",
    "        V_kplus1 = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "\n",
    "        for i, j in states:\n",
    "            for action, prob in zip(actions, ACTION_PROBS):\n",
    "                newPosition = nextState[i][j][action]\n",
    "\n",
    "                # Bellman update rule\n",
    "                V_kplus1[i, j] += prob * (REWARD + V_k[newPosition[0], newPosition[1]])\n",
    "\n",
    "        # Computes the sum of differences between last and new estimates\n",
    "        sum_of_diffs = np.sum(np.abs(V_kplus1 - V_k))\n",
    "\n",
    "        # Updates our current estimate\n",
    "        V_k = V_kplus1\n",
    "        k += 1\n",
    "\n",
    "    print('Random Policy : {} iterations'.format(k))\n",
    "    print(np.round(V_k))\n",
    "\n",
    "policy_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
